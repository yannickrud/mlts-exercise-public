{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLTS Exercise 02 - Bayesian Linear Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:\n",
    "\n",
    "This notebook provides three time series datasets, each representing daily user counts for separate applications over the year 2020:\n",
    "* `App_1_Users_2020.csv`\n",
    "* `App_2_Users_2020.csv`\n",
    "* `App_3_Users_2020.csv`\n",
    "\n",
    "In the previous exercise, you already took a look at the datasets and did some basic visual analysis.\n",
    "\n",
    "In this exercise, you will use Bayesian Linear Regression to analyse the datasets further and to get to know the method more in-depth. Additionally, you will use the method to do a simple forcasting on the time series.\n",
    "\n",
    "For each dataset, complete the following tasks:\n",
    "\n",
    "* Set up a Bayesian Linear Regression Model with PyMC on the train set and choose informative priors.\n",
    "* Check if the prior is choosen well and the model can actually predict the observed train set.\n",
    "* Draw samples for the posterior distribution to find the best parameters for the model.\n",
    "* Check if the sampled posterior can predict the observed train data.\n",
    "* Test if the model also works on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variables and functions\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def plot_xY(x, Y, ax):\n",
    "    \"\"\"This fuction plots the prediction\n",
    "\n",
    "    Args:\n",
    "        x: The date of the time series (train.index)\n",
    "        Y: The prediction by the model\n",
    "        ax: The matplotlib axis\n",
    "    \"\"\"\n",
    "    quantiles = Y.quantile((0.025, 0.25, 0.5, 0.75, 0.975), dim=(\"chain\", \"draw\")).transpose()\n",
    "\n",
    "    az.plot_hdi(\n",
    "        x,\n",
    "        hdi_data=quantiles.sel(quantile=[0.025, 0.975]),\n",
    "        fill_kwargs={\"alpha\": 0.25},\n",
    "        smooth=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "    az.plot_hdi(\n",
    "        x,\n",
    "        hdi_data=quantiles.sel(quantile=[0.25, 0.75]),\n",
    "        fill_kwargs={\"alpha\": 0.5},\n",
    "        smooth=False,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.plot(x, quantiles.sel(quantile=0.5), color=\"C1\", lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to data\n",
    "base_path = '../00_Datasets/01-03_App_Datasets'\n",
    "# path = 'App_1_Users_2020.csv'\n",
    "# path = 'App_2_Users_2020.csv'\n",
    "path = 'App_3_Users_2020.csv'\n",
    "\n",
    "path = os.path.join(base_path, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "data = pd.read_csv(path, sep=';', index_col='date')\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets, with the test set comprising the final three months of 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "split_time = '2020-10-01'\n",
    "train = data[data.index < split_time]\n",
    "test = data[data.index >= split_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test set\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = train[\"users\"].plot(label='train')\n",
    "test[\"users\"].plot(label='test')\n",
    "ax.axvline(split_time, c=\"k\", ls=\":\")\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Users')\n",
    "ax.grid()\n",
    "ax.set_title('Users over Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['users'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Let us build a Bayesian Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and setup a PyMC model\n",
    "with pm.Model() as model:\n",
    "    # register time to the model\n",
    "    tmp_time = train[\"time\"].to_numpy()\n",
    "    time = pm.Data(\"time\", tmp_time, dims=\"obs_id\")\n",
    "    time_2 = pm.Data(\"time_2\", tmp_time * tmp_time, dims=\"obs_id\")\n",
    "    time_3 = pm.Data(\"time_3\", tmp_time * tmp_time * tmp_time, dims=\"obs_id\")\n",
    "\n",
    "    # register priors\n",
    "    beta0 = pm.Normal(\"beta0\", 6200, 500)\n",
    "    beta1 = pm.Normal(\"beta1\", 60, 20)\n",
    "    beta2 = pm.Normal(\"beta2\", -0.2, 0.2)\n",
    "    beta3 = pm.Normal(\"beta3\", 0, 0.01)\n",
    "\n",
    "    sigma = pm.HalfNormal(\"sigma\", 2)\n",
    "\n",
    "    # the actual linear model\n",
    "    mu = beta0 + (beta1 * time) + (beta2 * time_2) + (beta3 * time_3)\n",
    "\n",
    "    # likelihood\n",
    "    pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=train[\"users\"].to_numpy(), dims=\"obs_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the created model\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the prior\n",
    "\n",
    "As part of the Bayesian workflow, we will plot our prior predictions to see what outcomes the model finds before having observed any data. Is the prior chosen well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prior\n",
    "with model:\n",
    "    idata = pm.sample_prior_predictive(random_seed=RANDOM_SEED)\n",
    "\n",
    "# plot the prior prediction\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plot_xY(train.index, idata.prior_predictive[\"obs\"], ax)\n",
    "ax = train[\"users\"].plot(label='observed')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Users')\n",
    "ax.grid()\n",
    "ax.set(title=\"Prior predictive distribution on train set\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Train\" the model\n",
    "\n",
    "Draw samples for the posterior distribution on the train set and find the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata.extend(pm.sample(random_seed=RANDOM_SEED, draws=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how the model tested out different samples of parameters\n",
    "az.plot_trace(idata)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictive check\n",
    "\n",
    "Another important aspect of the Bayesian workflow is to plot the model's posterior predictions, allowing us to see how well the model can predict the observed train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get posterior\n",
    "with model:\n",
    "    idata.extend(pm.sample_posterior_predictive(idata, random_seed=RANDOM_SEED))\n",
    "\n",
    "# plot the results\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plot_xY(train.index, idata.posterior_predictive[\"obs\"], ax)\n",
    "ax = train[\"users\"].plot(label='observed')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Users')\n",
    "ax.grid()\n",
    "ax.set(title=\"Posterior predictive distribution on train set\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on test set\n",
    "\n",
    "Now we will use our model to predict/forcast the expected number of users for the last 3 months of the year (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test data and predict its posterior from the model\n",
    "test_time = test[\"time\"].to_numpy()\n",
    "with model:\n",
    "    pm.set_data(\n",
    "        {\n",
    "            \"time\": test_time,\n",
    "            \"time_2\": test_time * test_time,\n",
    "            \"time_3\": test_time * test_time * test_time,\n",
    "        }\n",
    "    )\n",
    "    test_posterior = pm.sample_posterior_predictive(\n",
    "        idata, var_names=[\"obs\"], random_seed=RANDOM_SEED\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the posterior on the test set\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plot_xY(test.index, test_posterior.posterior_predictive[\"obs\"], ax)\n",
    "ax = test[\"users\"].plot(label='observed')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Users')\n",
    "ax.grid()\n",
    "ax.set(title=\"Posterior predictive distribution on test set\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test set with prediction\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "plot_xY(train.index, idata.posterior_predictive[\"obs\"], ax)\n",
    "plot_xY(test.index, test_posterior.posterior_predictive[\"obs\"], ax)\n",
    "ax = train[\"users\"].plot(label='train')\n",
    "test[\"users\"].plot(label='test', color='green')\n",
    "ax.axvline(split_time, c=\"k\", ls=\":\")\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Users')\n",
    "ax.grid()\n",
    "ax.set_title('Users over Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "This notebook is based on:\n",
    "Benjamin T. Vincent . \"Interrupted time series analysis\". In: PyMC Examples. Ed. by PyMC Team. DOI: [10.5281/zenodo.5654871](https://doi.org/10.5281/zenodo.5654871)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
